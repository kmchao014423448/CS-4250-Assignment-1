{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a266b106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your query:\n",
      "dog\n",
      "\n",
      "Tokenized query:  ['dog']\n",
      "\n",
      "Tokenized documents:  [' love cat  cat', ' love  dog', ' love  dog  cat']\n",
      "\n",
      "tfidf Matrix:  [[' ', 'love', 'cat', 'dog'], ['d1', 0.0, 0.11739417270378749, 0.0], ['d2', 0.0, 0.0, 0.08804562952784062], ['d3', 0.0, 0.058697086351893746, 0.058697086351893746]]\n",
      "\n",
      "Score for Document 1 :  0.11739417270378749\n",
      "Score for Document 2 :  0.08804562952784062\n",
      "Score for Document 3 :  0.11739417270378749\n",
      "\n",
      "binary query:  [0, 0, 1]\n",
      "\n",
      "The relevant documents with a score greater than .1 are:  [1, 3]\n",
      "The precision of this engine is:  50.0 %\n",
      "The recall of this engine is:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "#-------------------------------------------------------------------------\n",
    "# AUTHOR: Kyle Chao\n",
    "# FILENAME: #8 Code\n",
    "# SPECIFICATION: Submission for #8 on Assignment 1\n",
    "# FOR: CS 4250- Assignment #1\n",
    "# TIME SPENT: 42 Hours\n",
    "#-----------------------------------------------------------*/\n",
    "\n",
    "#IMPORTANT NOTE: DO NOT USE ANY ADVANCED PYTHON LIBRARY TO COMPLETE THIS CODE SUCH AS numpy OR pandas. You have to work here only with standard arrays\n",
    "\n",
    "#importing some Python libraries\n",
    "import csv\n",
    "import math\n",
    "\n",
    "documents = []\n",
    "labels = []\n",
    "\n",
    "#reading the data in a csv file\n",
    "with open('collection.csv', 'r') as csvfile:\n",
    "  reader = csv.reader(csvfile)\n",
    "  for i, row in enumerate(reader):\n",
    "        if i > 0:  # skipping the header\n",
    "            documents.append (row[0])\n",
    "            labels.append(row[1])\n",
    "\n",
    "            \n",
    "#Conduct stopword removal.\n",
    "#--> add your Python code here\n",
    "stopWords = {'I', 'and', 'She', 'They', 'her', 'their'}\n",
    "\n",
    "            \n",
    "            \n",
    "count=0\n",
    "\n",
    "for a in documents:\n",
    "\n",
    "   # print(a)\n",
    "    for i in stopWords:\n",
    "        \n",
    "        #print(i)\n",
    "        if i in a:\n",
    "            #print(count)\n",
    "            #print('yes')\n",
    "            a = a.replace(i,'')\n",
    "            #print(a)\n",
    "            documents[count] = a\n",
    "    count= count + 1\n",
    "            \n",
    "            \n",
    "\n",
    "         \n",
    "#Conduct stemming.\n",
    "#--> add your Python code here\n",
    "steeming = {\n",
    "  \"cats\": \"cat\",\n",
    "  \"dogs\": \"dog\",\n",
    "  \"loves\": \"love\",\n",
    "}\n",
    "counter = 0\n",
    "for a in documents:\n",
    "    #print(a)\n",
    "    for key in steeming:\n",
    "        if key in a:\n",
    "            #print('yes')\n",
    "            a = a.replace(key,steeming[key])\n",
    "            #print(a)\n",
    "            documents[counter] = a\n",
    "\n",
    "    counter = counter + 1\n",
    "    \n",
    "#print(documents)\n",
    "\n",
    "#Identify the index terms.\n",
    "#--> add your Python code here\n",
    "terms = []\n",
    "print('Enter your query:')\n",
    "\n",
    "\n",
    "query = input()\n",
    "print('')\n",
    "\n",
    "terms = query.split()\n",
    "\n",
    "\n",
    "\n",
    "counta=0\n",
    "for a in terms:\n",
    "\n",
    "    for i in stopWords:\n",
    "        \n",
    "        #print(i)\n",
    "        if i in terms:\n",
    "            a = a.replace(i,'')\n",
    "            #print(a)\n",
    "            terms[counta] = a\n",
    "    counta= counta + 1\n",
    "\n",
    "\n",
    "\n",
    "     \n",
    "    \n",
    "  \n",
    "\n",
    "counting=0\n",
    "\n",
    "for a in terms:\n",
    "    #print(a)\n",
    "    for key in steeming:\n",
    "        if key in a:\n",
    "            #print('yes')\n",
    "            a = a.replace(key,steeming[key])\n",
    "            terms[counting] = a\n",
    "\n",
    "    counting = counting + 1\n",
    "\n",
    "if '' in terms:\n",
    "\n",
    "    terms.remove('')\n",
    "\n",
    "print('Tokenized query: ',terms)\n",
    "print('')\n",
    "\n",
    "print('Tokenized documents: ',documents)\n",
    "print('')\n",
    "\n",
    "#Build the tf-idf term weights matrix.\n",
    "#--> add your Python code here\n",
    "docMatrix = []\n",
    "\n",
    "\n",
    "\n",
    "row = len(documents)\n",
    "a = ''\n",
    "\n",
    "columns=str()\n",
    "for a in documents:\n",
    "    columns= columns + a\n",
    "\n",
    "\n",
    "\n",
    "x= columns.split()\n",
    "\n",
    "term= []\n",
    "for a in x:\n",
    "    if a not in term:\n",
    "        term.append(a)\n",
    "\n",
    "\n",
    "\n",
    "column = len(term)\n",
    "\n",
    "\n",
    "\n",
    "docMatrix= [[' '] + term]\n",
    "\n",
    "\n",
    "\n",
    "county=1\n",
    "for a in range(row):\n",
    "    lit = []\n",
    "    lit = ['d'+str(county)] + (['']*column) \n",
    "    docMatrix.append(lit)\n",
    "    county=county+1\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "catcount=0\n",
    "dogcount=0\n",
    "lovecount=0\n",
    "    \n",
    "    \n",
    "for a in documents:\n",
    "    if 'cat' in a:\n",
    "        catcount= catcount+1\n",
    "    if 'dog' in a:\n",
    "        dogcount=dogcount+1\n",
    "    if 'love' in a:\n",
    "        lovecount=lovecount +1\n",
    "\n",
    "\n",
    "countset = 1\n",
    "\n",
    "\n",
    "tfidf = []\n",
    "loveidf=[]\n",
    "catidf=[]\n",
    "dogidf=[]\n",
    "\n",
    "for a in documents:\n",
    "    b=a.split()\n",
    "    #print(len(b))\n",
    "    countmove = 1\n",
    "    cat= 0\n",
    "    dog= 0\n",
    "    love= 0\n",
    "    x= columns.split()\n",
    "    cat = (a.count('cat'))\n",
    "    dog = (a.count('dog'))\n",
    "    love = (a.count('love'))\n",
    "    \n",
    "    \n",
    "    \n",
    "    tfcat = cat/len(b)\n",
    "    idfcat = math.log10(row/catcount)\n",
    "    tfidfcat = tfcat*idfcat\n",
    "    \n",
    "    \n",
    "    tfdog = dog/len(b)\n",
    "    idfdog = math.log10(row/dogcount)\n",
    "    tfidfdog = tfdog*idfdog\n",
    "    \n",
    "    \n",
    "    tflove = love/len(b)\n",
    "    idflove = math.log10(row/lovecount)\n",
    "    tfidflove = tflove*idflove\n",
    "    \n",
    "    loveidf.append(tfidflove)\n",
    "    catidf.append(tfidfcat)\n",
    "    dogidf.append(tfidfdog)\n",
    "    tfidf.append(tfidflove)\n",
    "    tfidf.append(tfidfcat)\n",
    "    tfidf.append(tfidfdog)\n",
    "\n",
    "\n",
    "setcount=1\n",
    "movecount=1\n",
    "throughcount=0\n",
    "\n",
    "for a in range(len(tfidf)):\n",
    "    docMatrix[setcount][movecount]=tfidf[throughcount]\n",
    "    movecount = movecount +1\n",
    "    throughcount = throughcount + 1\n",
    "    if movecount ==4:\n",
    "        movecount =1\n",
    "        setcount = setcount + 1\n",
    "    if throughcount > 8:\n",
    "        break\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "print('tfidf Matrix: ',docMatrix)   \n",
    "print('')\n",
    "\n",
    "    \n",
    "#Calculate the document scores (ranking) using document weigths (tf-idf) calculated before and query weights (binary - have or not the term).\n",
    "#--> add your Python code here\n",
    "docScores = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "countidf=0\n",
    "for a in range (len(catidf)):\n",
    "    docScores.append(loveidf[countidf]+catidf[countidf]+dogidf[countidf])\n",
    "    countidf=countidf+1\n",
    "\n",
    "#print(docScores)\n",
    "\n",
    "#term vs terms\n",
    "\n",
    "doccount=0\n",
    "for a in range(len(docScores)):\n",
    "    print('Score for Document',doccount+1,': ',docScores[doccount])\n",
    "    doccount=doccount+1\n",
    "binterm=[]\n",
    "countterms=0\n",
    "for a in term:\n",
    "    if a in terms:\n",
    "        binterm.append(1)\n",
    "    else:\n",
    "        binterm.append(0)\n",
    "print('')\n",
    "print('binary query: ',binterm)\n",
    "print('')\n",
    "#print(docScores)\n",
    "    \n",
    "#Calculate and print the precision and recall of the model by considering that the search engine will return all documents with scores >= 0.1.\n",
    "#--> add your Python code here\n",
    "\n",
    "retrievedoc=[]\n",
    "rcount=1\n",
    "\n",
    "for a in docScores:\n",
    "    if a > .1:\n",
    "        retrievedoc.append(rcount)\n",
    "    #print(rcount)\n",
    "    rcount=rcount+1\n",
    "    \n",
    "reldoc=[]\n",
    "ccount=0\n",
    "for a in term:\n",
    "    for b in term:\n",
    "        if a in b:\n",
    "            reldoc.append(ccount+1)\n",
    "            \n",
    "            \n",
    "    ccount=ccount+1\n",
    "\n",
    "    \n",
    "#print(documents)        \n",
    "\n",
    "#print(terms)\n",
    "#print(reldoc)\n",
    "hitdoc=[]\n",
    "acount=0\n",
    "for a in reldoc:\n",
    "    if docScores[acount]>.1:\n",
    "        hitdoc.append(a)\n",
    "    acount=acount+1    \n",
    "print('The relevant documents with a score greater than .1 are: ',hitdoc)\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "preclist=[]\n",
    "for a in terms:\n",
    "    pcount=1\n",
    "    for x in documents:\n",
    "        if a in x:\n",
    "            preclist.append(pcount)\n",
    "        pcount=pcount+1\n",
    "    \n",
    "\n",
    "\n",
    "plist=[]\n",
    "\n",
    "\n",
    "for a in set(preclist):\n",
    "    #print(int(a))\n",
    "    if docScores[int(a)-1]>.1:\n",
    "        plist.append(a)\n",
    "\n",
    "flist=[]\n",
    "hcount=0\n",
    "\n",
    "for a in plist:\n",
    "    if a == hitdoc[hcount]:\n",
    "        flist.append(1)\n",
    "    else:\n",
    "        flist.append(0)\n",
    "    hcount=hcount+1\n",
    "gcount=0\n",
    "fcount=0\n",
    "for a in flist:\n",
    "    fcount=fcount+1\n",
    "    gcount=int(a) + gcount\n",
    "\n",
    "    \n",
    "\n",
    "recall=gcount/fcount\n",
    "\n",
    "rlist=[]\n",
    "\n",
    "\n",
    "checkdoc=[]\n",
    "for a in documents:\n",
    "    c=a.split()\n",
    "    checkdoc.append(c)\n",
    "#print(checkdoc)\n",
    "\n",
    "for a in hitdoc:\n",
    "    if any(x in terms for x in checkdoc[int(a)-1]):\n",
    "        rlist.append(1)\n",
    "    else:\n",
    "        rlist.append(0)\n",
    "\n",
    "                \n",
    "#print(rlist)\n",
    "rcount=0\n",
    "gcount=0\n",
    "for a in rlist:\n",
    "    rcount=rcount+1\n",
    "    gcount=int(a)+gcount\n",
    "    \n",
    "precision=gcount/rcount\n",
    "\n",
    "print('The precision of this engine is: ',precision*100,'%')\n",
    "print('The recall of this engine is: ',recall*100,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcc233d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
